{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# **Extracting Data**"
      ],
      "metadata": {
        "id": "DzaFdNHRoHGJ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Choosing the Book**: Since my birth month is July (7), I will use Book 7 as per the given instructions.\n",
        "\n",
        "Extracting `file1.txt`: My birthdate is July 7, so I will extract 10 pages starting from page 7 of Book 7 and save them in `file1.txt`.\n",
        "\n",
        "Extracting `file2.txt`: My birth year is 2002, which corresponds to page 102. I will extract 10 pages starting from page 102 of Book 7 and save them in `file2.txt`."
      ],
      "metadata": {
        "id": "6KlAphr2ob7Q"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install pyspellchecker\n",
        "!pip install PyPDF2\n",
        "!pip install fpdf\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "D8CW0Bk0pnga",
        "outputId": "30e82e64-8c11-4362-fdf0-a66544d47b42"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting pyspellchecker\n",
            "  Downloading pyspellchecker-0.8.2-py3-none-any.whl.metadata (9.4 kB)\n",
            "Downloading pyspellchecker-0.8.2-py3-none-any.whl (7.1 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m7.1/7.1 MB\u001b[0m \u001b[31m64.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: pyspellchecker\n",
            "Successfully installed pyspellchecker-0.8.2\n",
            "Collecting PyPDF2\n",
            "  Downloading pypdf2-3.0.1-py3-none-any.whl.metadata (6.8 kB)\n",
            "Downloading pypdf2-3.0.1-py3-none-any.whl (232 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m232.6/232.6 kB\u001b[0m \u001b[31m3.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: PyPDF2\n",
            "Successfully installed PyPDF2-3.0.1\n",
            "Collecting fpdf\n",
            "  Downloading fpdf-1.7.2.tar.gz (39 kB)\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Building wheels for collected packages: fpdf\n",
            "  Building wheel for fpdf (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for fpdf: filename=fpdf-1.7.2-py2.py3-none-any.whl size=40704 sha256=52218e984a27294873bfcad27724254cc00ac0db5f1cbdec85a8ef25e8e55273\n",
            "  Stored in directory: /root/.cache/pip/wheels/65/4f/66/bbda9866da446a72e206d6484cd97381cbc7859a7068541c36\n",
            "Successfully built fpdf\n",
            "Installing collected packages: fpdf\n",
            "Successfully installed fpdf-1.7.2\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from PyPDF2 import PdfReader  # extract text from PDFs\n",
        "import re  # handle text processing with regular expressions\n",
        "import pandas as pd  # data manipulation and storage\n",
        "from collections import Counter  # count word occurrences\n",
        "from spellchecker import SpellChecker  # detect misspelled or non-English words\n",
        "from fpdf import FPDF  # create PDF reports\n",
        "import matplotlib.pyplot as plt  # generate visualizations\n"
      ],
      "metadata": {
        "id": "6-dbCJ10p0Mi"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# file paths\n",
        "PDF_FILE = \"/content/Harry_Potter_(www.ztcprep.com).pdf\"\n",
        "OUTPUT_FILE1 = \"file1.txt\"\n",
        "OUTPUT_FILE2 = \"file2.txt\"\n",
        "\n",
        "# birth details for book and page selection  July 7 2002\n",
        "BIRTH_MONTH, BIRTH_DATE, BIRTH_YEAR = 7, 7, 2002\n",
        "BOOK_ID = 7\n",
        "START_PAGE1 = BIRTH_DATE  # pages 7-16\n",
        "START_PAGE2 = 102  # pages 102-111\n",
        "\n",
        "from PyPDF2 import PdfReader\n",
        "\n",
        "def extract_pages(pdf_path, start_page, num_pages=10):\n",
        "    \"\"\"extracts text from specified page range in a PDF.\"\"\"\n",
        "    reader = PdfReader(pdf_path)\n",
        "    return \"\\n\".join(reader.pages[p - 1].extract_text() for p in range(start_page, start_page + num_pages) if p <= len(reader.pages))\n",
        "\n",
        "#extract and save text\n",
        "with open(OUTPUT_FILE1, \"w\", encoding=\"utf-8\") as f1, open(OUTPUT_FILE2, \"w\", encoding=\"utf-8\") as f2:\n",
        "    f1.write(extract_pages(PDF_FILE, START_PAGE1))\n",
        "    f2.write(extract_pages(PDF_FILE, START_PAGE2))\n",
        "\n",
        "print(f\"Text extraction complete: {OUTPUT_FILE1}, {OUTPUT_FILE2}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "T9Nf6T5AqdO3",
        "outputId": "eff656df-e0f8-4c4d-e7ce-f082042ad4ad"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Text extraction complete: file1.txt, file2.txt\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Q1**:  Write Python code and use MapReduct to count occurrences of each word in the first text file (file.txt). How many times each word is repeated?"
      ],
      "metadata": {
        "id": "lArn1o0Dq5GS"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "TEXT_FILE = \"/content/file1.txt\"\n",
        "OUTPUT_CSV = \"word_count.csv\"\n",
        "\n",
        "def extract_words(text):\n",
        "    return re.findall(r'\\b\\w+\\b', text.lower())\n",
        "\n",
        "# Read text from file\n",
        "with open(TEXT_FILE, \"r\", encoding=\"utf-8\") as file:\n",
        "    content = file.read()\n",
        "\n",
        "# Count word occurrences\n",
        "word_freq = Counter(extract_words(content))\n",
        "\n",
        "# Convert to DataFrame and sort\n",
        "df = pd.DataFrame(word_freq.items(), columns=[\"Word\", \"Count\"]).sort_values(by=\"Count\", ascending=False)\n",
        "\n",
        "# Save results to CSV\n",
        "df.to_csv(OUTPUT_CSV, index=False)\n",
        "\n",
        "# Display output\n",
        "print(\"\\nWord Frequency Analysis from file1.txt:\")\n",
        "print(df.to_string(index=False))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lOGG_DyArA62",
        "outputId": "94dc886b-1a0f-4e1e-ed1f-6519e89ca6c9"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Word Frequency Analysis from file1.txt:\n",
            "        Word  Count\n",
            "         the     79\n",
            "          he     79\n",
            "           a     44\n",
            "         and     39\n",
            "          to     35\n",
            "          of     34\n",
            "         was     34\n",
            "     dursley     33\n",
            "          it     32\n",
            "           t     30\n",
            "         his     28\n",
            "          in     25\n",
            "        that     25\n",
            "          mr     23\n",
            "          as     20\n",
            "          on     20\n",
            "        have     16\n",
            "         had     16\n",
            "      people     13\n",
            "          at     13\n",
            "        been     12\n",
            "        didn     12\n",
            "         mrs     11\n",
            "         com     10\n",
            "         www     10\n",
            "         all     10\n",
            "       harry     10\n",
            "     ztcprep     10\n",
            "      potter      9\n",
            "        them      9\n",
            "         but      9\n",
            "        were      9\n",
            "           s      9\n",
            "        owls      9\n",
            "        into      9\n",
            "        said      8\n",
            "          be      8\n",
            "           d      8\n",
            "         cat      8\n",
            "        they      8\n",
            "        back      7\n",
            "       about      7\n",
            "          if      7\n",
            "       there      7\n",
            "         for      7\n",
            "           i      7\n",
            "         him      7\n",
            "           e      7\n",
            "          no      7\n",
            "         her      7\n",
            "     thought      7\n",
            "        this      6\n",
            "   something      6\n",
            "       could      6\n",
            "      couldn      6\n",
            "     rowling      6\n",
            "           k      6\n",
            "           j      6\n",
            "       stone      6\n",
            "philosophers      6\n",
            "           g      6\n",
            "           p      6\n",
            "        over      6\n",
            "        when      6\n",
            "        with      5\n",
            "        even      5\n",
            "      drills      5\n",
            "     potters      5\n",
            "         you      5\n",
            "           w      5\n",
            "          so      5\n",
            "     himself      5\n",
            "        mind      5\n",
            "       their      4\n",
            "       today      4\n",
            "       still      4\n",
            "      cloaks      4\n",
            "        very      4\n",
            "         see      4\n",
            "       might      4\n",
            "        know      4\n",
            "         lot      4\n",
            "         not      4\n",
            "         why      4\n",
            "         man      4\n",
            "         she      4\n",
            "         now      4\n",
            "     morning      4\n",
            "        what      4\n",
            "        fell      4\n",
            "        next      4\n",
            "          an      4\n",
            "        down      4\n",
            "          by      4\n",
            "      sister      4\n",
            "        name      4\n",
            "         owl      4\n",
            "      called      4\n",
            "        eyes      3\n",
            "        last      3\n",
            "       heard      3\n",
            "       these      3\n",
            "        made      3\n",
            "         bed      3\n",
            "    normally      3\n",
            "          me      3\n",
            "         few      3\n",
            "     petunia      3\n",
            "         son      3\n",
            "       drive      3\n",
            "      around      3\n",
            "       until      3\n",
            "        door      3\n",
            "          up      3\n",
            "         yes      3\n",
            "        sign      3\n",
            "      privet      3\n",
            "           f      3\n",
            "        just      3\n",
            "      normal      3\n",
            "        same      3\n",
            "    shooting      3\n",
            "    daylight      3\n",
            "         day      3\n",
            "        town      3\n",
            "        sure      3\n",
            "    anything      3\n",
            "         sat      3\n",
            "           y      3\n",
            "         got      3\n",
            "       never      3\n",
            "         out      3\n",
            "        seen      3\n",
            "         put      3\n",
            "        road      3\n",
            "      dudley      3\n",
            "       upset      3\n",
            "      before      3\n",
            "         say      3\n",
            "      almost      3\n",
            "         how      3\n",
            "       stars      3\n",
            "         who      3\n",
            "       funny      3\n",
            "       night      3\n",
            "      corner      2\n",
            "        five      2\n",
            "       after      2\n",
            "      across      2\n",
            "        mood      2\n",
            "    overhead      2\n",
            "        good      2\n",
            "        most      2\n",
            "   telephone      2\n",
            "          do      2\n",
            "        more      2\n",
            "      flying      2\n",
            "     tonight      2\n",
            "         old      2\n",
            "       being      2\n",
            "     snapped      2\n",
            "     mention      2\n",
            "         any      2\n",
            "        home      2\n",
            "      number      2\n",
            "     changed      2\n",
            "        wasn      2\n",
            "  mysterious      2\n",
            "      stared      2\n",
            "     instead      2\n",
            "        tell      2\n",
            "        come      2\n",
            "       think      2\n",
            "         far      2\n",
            "     hurried      2\n",
            "        like      2\n",
            "      looked      2\n",
            "         ell      2\n",
            "       drove      2\n",
            "     whisper      2\n",
            "        dear      2\n",
            "         two      2\n",
            "       going      2\n",
            "         tea      2\n",
            "      walked      2\n",
            "      uneasy      2\n",
            "     outside      2\n",
            "      passed      2\n",
            "       sorry      2\n",
            "         jim      2\n",
            "        from      2\n",
            "         don      2\n",
            "          ge      2\n",
            "        bear      2\n",
            "     looking      2\n",
            "      hugged      2\n",
            "      garden      2\n",
            "  collecting      2\n",
            "     sitting      2\n",
            "         saw      2\n",
            "       young      2\n",
            "        gave      2\n",
            "        news      2\n",
            "       cloak      2\n",
            "        some      2\n",
            "     wearing      2\n",
            "        well      2\n",
            "      stupid      2\n",
            "      asleep      2\n",
            " celebrating      2\n",
            "         car      2\n",
            "         new      2\n",
            "         did      2\n",
            "   imagining      2\n",
            "    together      2\n",
            "   excitedly      2\n",
            "  whispering      2\n",
            "      things      2\n",
            "        room      2\n",
            "       quite      2\n",
            "      living      2\n",
            "        went      2\n",
            "          or      2\n",
            "       happy      2\n",
            "        word      2\n",
            "        wall      2\n",
            "      window      2\n",
            "         are      2\n",
            "       found      2\n",
            "      harder      2\n",
            "     dressed      2\n",
            " concentrate      2\n",
            "        fice      2\n",
            "        traf      2\n",
            "         get      2\n",
            "         fic      2\n",
            "        past      2\n",
            "    wondered      2\n",
            "      hoping      2\n",
            "      always      2\n",
            "      though      2\n",
            "      street      2\n",
            "         its      2\n",
            "    thinking      2\n",
            "         lar      2\n",
            "     nothing      2\n",
            "      acting      1\n",
            "        only      1\n",
            "  weatherman      1\n",
            "  determined      1\n",
            "     learned      1\n",
            "           6      1\n",
            "       house      1\n",
            "        wife      1\n",
            "       oddly      1\n",
            "        nice      1\n",
            "        told      1\n",
            "           v      1\n",
            "    daughter      1\n",
            "      iewers      1\n",
            "    problems      1\n",
            "       tried      1\n",
            "      dinner      1\n",
            "        ever      1\n",
            "       mcguf      1\n",
            "         act      1\n",
            "       since      1\n",
            "     pattern      1\n",
            "    sleeping      1\n",
            "    suddenly      1\n",
            "     explain      1\n",
            "      unable      1\n",
            "     experts      1\n",
            "     sunrise      1\n",
            "   direction      1\n",
            "          ed      1\n",
            "        hunt      1\n",
            "       every      1\n",
            "       birds      1\n",
            "      hardly      1\n",
            "   sightings      1\n",
            "        kent      1\n",
            "    hundreds      1\n",
            "    although      1\n",
            "   unusually      1\n",
            "    behaving      1\n",
            "  newscaster      1\n",
            "     showers      1\n",
            "     weather      1\n",
            "         fin      1\n",
            "        time      1\n",
            "       catch      1\n",
            "      report      1\n",
            "     evening      1\n",
            "     finally      1\n",
            "        bird      1\n",
            "    watchers      1\n",
            "  everywhere      1\n",
            "        grin      1\n",
            "     allowed      1\n",
            "    reported      1\n",
            "      nation      1\n",
            "       apart      1\n",
            "       haven      1\n",
            "    orkshire      1\n",
            "       nasty      1\n",
            "       awake      1\n",
            "         lay      1\n",
            "     quickly      1\n",
            "    dursleys      1\n",
            "        pair      1\n",
            "     related      1\n",
            "     waiting      1\n",
            "     staring      1\n",
            "       front      1\n",
            "      peered      1\n",
            "           8      1\n",
            "     bedroom      1\n",
            "       crept      1\n",
            "    bathroom      1\n",
            "       while      1\n",
            "    upstairs      1\n",
            "     subject      1\n",
            "     another      1\n",
            "       agree      1\n",
            "          es      1\n",
            "    horribly      1\n",
            "     sinking      1\n",
            "       heart      1\n",
            "          oh      1\n",
            "         ask      1\n",
            "     turning      1\n",
            "  comforting      1\n",
            "         wer      1\n",
            "     showing      1\n",
            "      nearly      1\n",
            "        fact      1\n",
            "     swooped      1\n",
            "         nor      1\n",
            "     slammed      1\n",
            "      quiver      1\n",
            "        much      1\n",
            "unblinkingly      1\n",
            "       fixed      1\n",
            "      statue      1\n",
            "  sleepiness      1\n",
            "       sleep      1\n",
            "    involved      1\n",
            "    drifting      1\n",
            "       wrong      1\n",
            "        fect      1\n",
            "          af      1\n",
            "      turned      1\n",
            "      yawned      1\n",
            "       mixed      1\n",
            "        kind      1\n",
            "        knew      1\n",
            "        near      1\n",
            "      reason      1\n",
            "      common      1\n",
            "         isn      1\n",
            "      dundee      1\n",
            "      howard      1\n",
            "   nervously      1\n",
            "      throat      1\n",
            "     cleared      1\n",
            "        cups      1\n",
            "    carrying      1\n",
            "        came      1\n",
            "           7      1\n",
            "       place      1\n",
            "     britain      1\n",
            "    armchair      1\n",
            "      frozen      1\n",
            "         wet      1\n",
            "     promise      1\n",
            "         can      1\n",
            "       folks      1\n",
            "        week      1\n",
            "       early      1\n",
            "     bonfire      1\n",
            "     perhaps      1\n",
            "    downpour      1\n",
            "          ve      1\n",
            "   yesterday      1\n",
            "    promised      1\n",
            "        rain      1\n",
            "     phoning      1\n",
            "          er      1\n",
            "        pull      1\n",
            "        your      1\n",
            "        lips      1\n",
            "       again      1\n",
            "         fly      1\n",
            "        stif      1\n",
            "     suppose      1\n",
            "      wouldn      1\n",
            "         age      1\n",
            "    casually      1\n",
            "        dare      1\n",
            "     decided      1\n",
            "       dared      1\n",
            "     whether      1\n",
            "      pursed      1\n",
            "      lately      1\n",
            "     through      1\n",
            "      sipped      1\n",
            "       crowd      1\n",
            "       maybe      1\n",
            "     mumbled      1\n",
            "        stuf      1\n",
            "     sharply      1\n",
            "   pretended      1\n",
            "       angry      1\n",
            "     shocked      1\n",
            "    expected      1\n",
            "         let      1\n",
            "     knocked      1\n",
            "       rying      1\n",
            "        sped      1\n",
            "           4      1\n",
            "   important      1\n",
            "     several      1\n",
            "      ferent      1\n",
            "         dif      1\n",
            "      yelled      1\n",
            "        free      1\n",
            "   perfectly      1\n",
            "     however      1\n",
            "   nighttime      1\n",
            "     mouthed      1\n",
            "     parking      1\n",
            "        open      1\n",
            "       gazed      1\n",
            "     pointed      1\n",
            "       broad      1\n",
            "    swooping      1\n",
            "     watched      1\n",
            "      mirror      1\n",
            "        hadn      1\n",
            "       floor      1\n",
            "       ninth      1\n",
            "       calls      1\n",
            "     shouted      1\n",
            "         bit      1\n",
            "   lunchtime      1\n",
            "       words      1\n",
            "      caught      1\n",
            "         bag      1\n",
            "    doughnut      1\n",
            "   clutching      1\n",
            "         way      1\n",
            "         tin      1\n",
            "      single      1\n",
            "         too      1\n",
            "       bunch      1\n",
            "     angrily      1\n",
            "        eyed      1\n",
            "       baker      1\n",
            "       group      1\n",
            "      gotten      1\n",
            "      bakery      1\n",
            "         bun      1\n",
            "         buy      1\n",
            "        walk      1\n",
            "        legs      1\n",
            "     stretch      1\n",
            "     reading      1\n",
            "   grunnings      1\n",
            "    behavior      1\n",
            "       shake      1\n",
            "      huddle      1\n",
            "       wheel      1\n",
            "    steering      1\n",
            "     fingers      1\n",
            "     drummed      1\n",
            "     fashion      1\n",
            "    supposed      1\n",
            "      getups      1\n",
            "     clothes      1\n",
            "      little      1\n",
            "   strangely      1\n",
            "     arrived      1\n",
            "      seemed      1\n",
            "    noticing      1\n",
            "        help      1\n",
            "         jam      1\n",
            "       usual      1\n",
            "        else      1\n",
            "      driven      1\n",
            "      toward      1\n",
            "        edge      1\n",
            "      except      1\n",
            "       signs      1\n",
            "        maps      1\n",
            "     weirdos      1\n",
            "    standing      1\n",
            "       later      1\n",
            "     minutes      1\n",
            "       moved      1\n",
            "       would      1\n",
            "   obviously      1\n",
            "       stunt      1\n",
            "       silly      1\n",
            "    probably      1\n",
            "      struck      1\n",
            "        then      1\n",
            "       nerve      1\n",
            "       green      1\n",
            "     emerald      1\n",
            "        than      1\n",
            "       older      1\n",
            "       weren      1\n",
            "        cats      1\n",
            "      couple      1\n",
            "     enraged      1\n",
            "        read      1\n",
            "       close      1\n",
            "      saying      1\n",
            "       right      1\n",
            "           3      1\n",
            "        gone      1\n",
            "        also      1\n",
            "    stranger      1\n",
            "    complete      1\n",
            "        spot      1\n",
            "      rooted      1\n",
            "       stood      1\n",
            "      middle      1\n",
            "      should      1\n",
            "    yourself      1\n",
            "     muggles      1\n",
            "         has      1\n",
            "     stopped      1\n",
            "          ou      1\n",
            "     rejoice      1\n",
            "         sir      1\n",
            "          my      1\n",
            "       stare      1\n",
            "   passersby      1\n",
            "       voice      1\n",
            "     squeaky      1\n",
            "       smile      1\n",
            "        wide      1\n",
            "      muggle      1\n",
            "    whatever      1\n",
            "     rattled      1\n",
            "         set      1\n",
            "        must      1\n",
            "        look      1\n",
            "       stern      1\n",
            "        move      1\n",
            "      loudly      1\n",
            "        shoo      1\n",
            "    markings      1\n",
            "         one      1\n",
            "     spotted      1\n",
            "       tabby      1\n",
            "     improve      1\n",
            "       thing      1\n",
            "       first      1\n",
            "        four      1\n",
            "    driveway      1\n",
            "      pulled      1\n",
            " imagination      1\n",
            "     approve      1\n",
            "     because      1\n",
            "       hoped      1\n",
            "       which      1\n",
            "       split      1\n",
            "        face      1\n",
            "    contrary      1\n",
            "       point      1\n",
            "      harvey      1\n",
            "         boy      1\n",
            "      nephew      1\n",
            "        lots      1\n",
            "     unusual      1\n",
            "        such      1\n",
            "    mustache      1\n",
            "     stroked      1\n",
            "    receiver      1\n",
            "     dialing      1\n",
            "    finished      1\n",
            "      seized      1\n",
            "     disturb      1\n",
            "   secretary      1\n",
            "      dashed      1\n",
            "      better      1\n",
            "      wanted      1\n",
            "  whisperers      1\n",
            "     flooded      1\n",
            "        fear      1\n",
            "        dead      1\n",
            "      harold      1\n",
            "    worrying      1\n",
            "      ground      1\n",
            "     blinked      1\n",
            "       order      1\n",
            "        seem      1\n",
            "      violet      1\n",
            "    realized      1\n",
            "     seconds      1\n",
            "    stumbled      1\n",
            "        tiny      1\n",
            "     grunted      1\n",
            "     someone      1\n",
            "       trick      1\n",
            "    straight      1\n",
            "     worried      1\n",
            "       clock      1\n",
            "           o      1\n",
            "    building      1\n",
            "        left      1\n",
            "   afternoon      1\n",
            "           5      1\n",
            "       those      1\n",
            "       blame      1\n",
            "       light      1\n",
            "    midnight      1\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Q2**: From the second text file (file2.txt), write Python code and use MapReduct to count how many times non-English words (names, places, spells etc.) were used. List those words and how many times each was repeated.\n",
        "\n"
      ],
      "metadata": {
        "id": "BunMvAG0rREF"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "FILE_PATH = \"/content/file2.txt\"\n",
        "OUTPUT_FILE = \"non_english_words.csv\"\n",
        "\n",
        "# Initialize spell checker\n",
        "spell_checker = SpellChecker()\n",
        "\n",
        "def get_words(text):\n",
        "    return re.findall(r'\\b\\w+\\b', text.lower())\n",
        "\n",
        "# Read text from file\n",
        "with open(FILE_PATH, \"r\", encoding=\"utf-8\") as file:\n",
        "    content = file.read()\n",
        "\n",
        "# Extract words and filter non-English words\n",
        "words = get_words(content)\n",
        "non_english = [word for word in words if word not in spell_checker]\n",
        "\n",
        "# Count occurrences\n",
        "word_counts = Counter(non_english)\n",
        "\n",
        "# Convert to DataFrame and save\n",
        "df = pd.DataFrame(word_counts.items(), columns=[\"Non-English Word\", \"Count\"]).sort_values(by=\"Count\", ascending=False)\n",
        "df.to_csv(OUTPUT_FILE, index=False)\n",
        "\n",
        "# Display results\n",
        "print(\"\\nIdentified Non-English Words from file2.txt:\")\n",
        "print(df.to_string(index=False))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qKw5IRs8rQq0",
        "outputId": "8c2ded7f-b010-4f7b-a543-78c51379540e"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Identified Non-English Words from file2.txt:\n",
            "Non-English Word  Count\n",
            "          hagrid     29\n",
            "             ter     23\n",
            "             yeh     13\n",
            "             www     10\n",
            "         ztcprep     10\n",
            "              ll      7\n",
            "       gringotts      7\n",
            "            didn      6\n",
            "           ernon      5\n",
            "              ap      3\n",
            "            stuf      3\n",
            "              ve      3\n",
            "          izards      2\n",
            "             eah      2\n",
            "            hadn      2\n",
            "           knuts      2\n",
            "           albus      2\n",
            "            wasn      2\n",
            "          gettin      2\n",
            "          wouldn      1\n",
            "              mm      1\n",
            "             teh      1\n",
            "              69      1\n",
            "              64      1\n",
            "              70      1\n",
            "            cept      1\n",
            "       deliverin      1\n",
            "       everythin      1\n",
            "          pposed      1\n",
            "       mentionin      1\n",
            "              71      1\n",
            "         guardin      1\n",
            "         fetchin      1\n",
            "              66      1\n",
            "           payin      1\n",
            "         shouldn      1\n",
            "          muggle      1\n",
            "            goin      1\n",
            "         dumbled      1\n",
            "            ying      1\n",
            "           insul      1\n",
            "              65      1\n",
            "         speakin      1\n",
            "              68      1\n",
            "            aren      1\n",
            "          meself      1\n",
            "              ou      1\n",
            "              67      1\n",
            "          diagon      1\n",
            "            ther      1\n",
            "           tryin      1\n"
          ]
        }
      ]
    }
  ]
}